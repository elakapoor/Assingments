{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING conda.base.context:use_only_tar_bz2(632): Conda is constrained to only using the old .tar.bz2 file format because you have conda-build installed, and it is <3.18.3.  Update or remove conda-build to get smaller downloads and faster extractions.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "    - torchvision\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2019.3.9           |           py37_0         155 KB\n",
      "    conda-4.7.10               |           py37_0         3.0 MB\n",
      "    ninja-1.9.0                |   py37h04f5b5a_0          96 KB\n",
      "    pytorch-1.1.0              |          py3.7_0        49.9 MB  pytorch\n",
      "    torchvision-0.3.0          |    py37_cuNone_1         1.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        54.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ninja              pkgs/main/osx-64::ninja-1.9.0-py37h04f5b5a_0\n",
      "  pytorch            pytorch/osx-64::pytorch-1.1.0-py3.7_0\n",
      "  torchvision        pytorch/osx-64::torchvision-0.3.0-py37_cuNone_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                     conda-forge::conda-4.7.5-py37_0 --> pkgs/main::conda-4.7.10-py37_0\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi                                       conda-forge --> pkgs/main\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pytorch-1.1.0        | 49.9 MB   | ##################################### | 100% \n",
      "conda-4.7.10         | 3.0 MB    | ##################################### | 100% \n",
      "ninja-1.9.0          | 96 KB     | ##################################### | 100% \n",
      "certifi-2019.3.9     | 155 KB    | ##################################### | 100% \n",
      "torchvision-0.3.0    | 1.7 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/os.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from IPython.display import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "# load the autoreload extension\n",
    "%load_ext autoreload\n",
    "# Set extension to reload modules every time before executing code\n",
    "#%autoreload 2\n",
    "#\n",
    "## Easy to read version\n",
    "#%system date\n",
    "#\n",
    "## Shorthand with \"!!\" instead of \"%system\" works equally well\n",
    "#!!date\n",
    "#!!ls\n",
    "#\n",
    "## Outputs a list of all interactive variables in your environment\n",
    "#%who_ls\n",
    "#\n",
    "## Reduces the output to interactive variables of type \"function\"\n",
    "#%who_ls function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is and WHY Use PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  **An extensible alternative for NumPy harnessing the power of GPUs**\n",
    "-  a **deep learning research platform that provides maximum flexibility\n",
    "   and speed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generation\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
    "\n",
    "# Shuffles the indices\n",
    "idx = np.arange(100)\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "# Uses first 80 random indices for train\n",
    "train_idx = idx[:80]\n",
    "# Uses the remaining indices for validation\n",
    "val_idx = idx[80:]\n",
    "\n",
    "# Generates train and validation sets\n",
    "x_train, y_train = x[train_idx], y[train_idx]\n",
    "x_val, y_val = x[val_idx], y[val_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In your own words, what is the relation between backpropagation used in neural networks and Automatic Differentiation ? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimise the function, one obvious approach is to use steepest descent: start with random values for the parameters to be estimated, find the direction in which the the function decreases most quickly, step a small amount in that direction and repeat until close enough.\n",
    "\n",
    "But we have two problems:\n",
    "\n",
    "1. We have an algorithm or a computer program that calculates the non-linear function rather than the function itself.\n",
    "\n",
    "2. The function has a very large number of parameters, hundreds if not thousands.\n",
    "\n",
    "One thing we could try is bumping each parameter by a small amount to get partial derivatives numerically\n",
    "\n",
    "$$\\displaystyle   \\frac{\\partial E(\\ldots, w, \\ldots)}{\\partial w} \\approx \\frac{E(\\ldots, w + \\epsilon, \\ldots) - E(\\ldots, w, \\ldots)}{\\epsilon}  $$\n",
    "\n",
    "But this would mean evaluating our function many times and moreover we could easily get numerical errors as a result of the vagaries of floating point arithmetic.\n",
    "\n",
    "The standard approach is to use a technique called backpropagation and the understanding and application of this technique forms a large part of many machine learning lecture courses.\n",
    "\n",
    "\n",
    "To elaborate a bit, you can compute the derivative of the loss with respect to all your weights naively one by one, but that is very wasteful as for every weight you end up retracing the derivative from that weight all the way to the loss without reusing any derivatives of other weights you might have computed previously.\n",
    "\n",
    "A more efficient method using backpropagation is to first compute the derivative of the loss with respect to the weights of the last layer, keep this in memory and use those gradients to compute the derivative of the loss with respect to the weights of the next-to-last layer using the chain rule. Note that to get the derivative of the loss with respect to layer n-1 you only need the derivative of the loss with respect to layer n. By applying this method until you get to the first layer, in a single backwards swoop you get all the derivatives.\n",
    "\n",
    "AD is just a general method of differentiating quantities with respect to others in a computational graph so indeed backpropagation is a specific subcase of AD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /anaconda3/lib/python3.7/site-packages (1.8)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.16.2)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /anaconda3/lib/python3.7/site-packages (from tensorboardX) (3.8.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from protobuf>=3.2.0->tensorboardX) (40.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accessing predefined path\n",
      "Iteration: 0 - Error: 22613632.0000\n",
      "Iteration: 50 - Error: 13316.2012\n",
      "Iteration: 100 - Error: 391.1063\n",
      "Iteration: 150 - Error: 18.3813\n",
      "Iteration: 200 - Error: 1.0917\n",
      "Iteration: 250 - Error: 0.0778\n",
      "Iteration: 300 - Error: 0.0067\n",
      "Iteration: 350 - Error: 0.0009\n",
      "Iteration: 400 - Error: 0.0002\n",
      "Iteration: 450 - Error: 0.0001\n",
      "Iteration: 500 - Error: 0.0000\n",
      "Iteration: 550 - Error: 0.0000\n",
      "Iteration: 600 - Error: 0.0000\n",
      "Iteration: 650 - Error: 0.0000\n",
      "Iteration: 700 - Error: 0.0000\n",
      "Iteration: 750 - Error: 0.0000\n",
      "Iteration: 800 - Error: 0.0000\n",
      "Iteration: 850 - Error: 0.0000\n",
      "Iteration: 900 - Error: 0.0000\n",
      "Iteration: 950 - Error: 0.0000\n",
      "Iteration: 1000 - Error: 0.0000\n",
      "Iteration: 1050 - Error: 0.0000\n",
      "Iteration: 1100 - Error: 0.0000\n",
      "Iteration: 1150 - Error: 0.0000\n",
      "Iteration: 1200 - Error: 0.0000\n",
      "Iteration: 1250 - Error: 0.0000\n",
      "Iteration: 1300 - Error: 0.0000\n",
      "Iteration: 1350 - Error: 0.0000\n",
      "Iteration: 1400 - Error: 0.0000\n",
      "Iteration: 1450 - Error: 0.0000\n",
      "Iteration: 1500 - Error: 0.0000\n",
      "Iteration: 1550 - Error: 0.0000\n",
      "Iteration: 1600 - Error: 0.0000\n",
      "Iteration: 1650 - Error: 0.0000\n",
      "Iteration: 1700 - Error: 0.0000\n",
      "Iteration: 1750 - Error: 0.0000\n",
      "Iteration: 1800 - Error: 0.0000\n",
      "Iteration: 1850 - Error: 0.0000\n",
      "Iteration: 1900 - Error: 0.0000\n",
      "Iteration: 1950 - Error: 0.0000\n",
      "Iteration: 2000 - Error: 0.0000\n",
      "Iteration: 2050 - Error: 0.0000\n",
      "Iteration: 2100 - Error: 0.0000\n",
      "Iteration: 2150 - Error: 0.0000\n",
      "Iteration: 2200 - Error: 0.0000\n",
      "Iteration: 2250 - Error: 0.0000\n",
      "Iteration: 2300 - Error: 0.0000\n",
      "Iteration: 2350 - Error: 0.0000\n",
      "Stopping gradient descent, algorithm converged, MSE loss is smaller than 1E-6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "log_path = './runs/gd/'\n",
    "\n",
    "if log_path:\n",
    "    print(\"accessing predefined path\")\n",
    "    writer = SummaryWriter(log_dir=log_path)\n",
    "else :\n",
    "    print(\"using new path set\")\n",
    "    writer = SummaryWriter(log_dir='./runs/gd/')\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create input and output variables x, and y \n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create weights of the hypothesis function\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "errors = []\n",
    "weights_1_out = []\n",
    "weights_2_out = []\n",
    "\n",
    "num_iterations = 5000\n",
    "\n",
    "for iteration in range(num_iterations):\n",
    "    # x*w1 -> relu -> * x2\n",
    "    y_pred = F.relu(x.mm(w1).clamp(min=0)).mm(w2)\n",
    "    \n",
    "    # rmse error\n",
    "    error = (y_pred - y).pow(2).sum()\n",
    "    error.backward()\n",
    "    \n",
    "    writer.add_scalar(tag=\"Last run\",scalar_value= error, global_step = iteration)\n",
    "    writer.add_histogram(\"error distribution\",error)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w1.data -= learning_rate * w1.grad.data\n",
    "        w2.data -= learning_rate * w2.grad.data\n",
    "        \n",
    "    if iteration % 50 == 0:\n",
    "        # print errors at each 50th iteration\n",
    "        print(\"Iteration: %d - Error: %.4f\" % (iteration, error.item()))\n",
    "        weights_1_out.append(w1.cpu().detach().numpy())\n",
    "        weights_1_out.append(w2.cpu().detach().numpy())\n",
    "        errors.append(error.cpu().detach().numpy())\n",
    "\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n",
    "    \n",
    "    # stopping criterion\n",
    "    if error.item() < 1e-6:\n",
    "        print(\"Stopping gradient descent, algorithm converged, MSE loss is smaller than 1E-6\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
