{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a likelihood function? Also add a formula. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many probability distributions have unknown parameters; We estimate these unknowns using sample data. The Likelihood function gives us an idea of how well the data summarizes these parameters.<br>\n",
    "Although a likelihood function might look just like a probability density function, it’s fundamentally different. A probability density function is a function of x, your data point, and it will tell you how likely it is that certain data points appear. A likelihood function, on the other hand, takes the data set as a given, and represents the likeliness of different parameters for your distribution.<br>\n",
    "Defining Likelihood Functions in Terms of Probability Density Functions\n",
    "Suppose the joint probability density function of your sample $ X = (X1,…X2) is f(x| θ) $, where θ is a parameter.$ X = x $is an observed sample point. Then the function of θ defined as\n",
    "\n",
    "$$ L(θ |x) = f(x |θ)$$\n",
    "\n",
    "is your likelihood function.<br>\n",
    "Here it certainly looks like we’re just taking our probability density function and cleverly relabeling it as a likelihood function. The reality, though, is actually quite different. For your probability density function, you thought of θ as a constant and focused on an ever changing x. In the likelihood function, you let a sample point x be a constant and imagine θ to be varying over the whole range of possible parameter values.<br>\n",
    "\n",
    "If we compare two points on our probability density function, we’ll be looking at two different values of x and examining which one has more probability of occurring. But for the likelihood function, we compare two different parameter points. For example, if we find that $L(θ1 | x) > L(θ2 | x)$, we know that our observed point x is more likely to have been observed under parameter conditions $θ = θ1$ rather than $θ = θ2$.<br>\n",
    "\n",
    "__Properties of Likelihoods__<br>\n",
    "Unlike probability density functions, likelihoods aren’t normalized. The area under their curves does not have to add up to 1.<br>\n",
    "\n",
    "In fact, we can only define a likelihood function up to a constant of proportionality. What that means that, rather then being one function, likelihood is an equivalence class of functions.<br>\n",
    "\n",
    "__Using Likelihoods__<br>\n",
    "Likelihoods are a key part of Bayesian inference. We also use likelihoods to generate estimators; we almost always want the maximum likelihood estimator.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Maximum Likelihood estimation (MLE) ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood estimation is a method that determines values for the parameters of a model. The parameter values are found such that they maximise the likelihood that the process described by the model produced the data that were actually observed.<br>\n",
    "The principle of Maximum Likelihood is at the heart of Machine Learning. It guides us to find the best model in a search space of all models. In simple terms, Maximum Likelihood Estimation or MLE lets us choose a model (parameters) that explains the data (training set) better than all other models. For any given neural network architecture, the objective function can be derived based on the principle of Maximum Likelihood.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of a statistical model given observations, by finding the parameter values that maximize the likelihood of making the observations given the parameters. MLE can be seen as a special case of the maximum a posteriori estimation (MAP) that assumes a uniform prior distribution of the parameters, or as a variant of the MAP that ignores the prior and which therefore is unregularized.<br>\n",
    "MLE in a nutshell helps us answer this question:Which are the best parameters/coefficients for my model?<br>\n",
    "The distinction between probability and likelihood is fundamentally important: Probability attaches to possible results; likelihood attaches to hypotheses.<br>\n",
    "Maximum likelihood estimation (MLE) is a technique used for estimating the parameters of a given distribution, using some observed data. For example, if a population is known to follow a “normal distribution” but the “mean” and “variance” are unknown, MLE can be used to estimate them using a limited sample of the population. MLE does that by finding particular values for the parameters (mean and variance) so that the resultant model with those parameters (mean and variance) would have generated the data.<br>\n",
    "So generally, likelihood expression is in the form of: L(parameters | data ). Meaning of this is, “likelihood of having these parameters, once the data are these”.<br>\n",
    "Likelihood and Probability are two different things although they look and behaves same. We talk about probability when we know the model parameters and when predicting a value from that model. So there we talk about how probable is the resultant value to be come out from that model. So probability is: P(data | parameters)<br>\n",
    "Now we can see that Likelihood is other side of probability. That is we are going to guess the model parameters from the data. So there we know the results well and we know for sure that they have occured (probability = 1)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is linear regression related to Pytorch and gradient descent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression related to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is an approach that tries to find a linear relationship between a dependent variable and an independent variable by minimizing the distance.<br>\n",
    "Let’s consider a very basic linear equation i.e., y=2x+1. Here, ‘x’ is the independent variable and y is the dependent variable. We’ll use this equation to create a dummy dataset which will be used to train this linear regression model. Following is the code for creating the dataset.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(4., requires_grad=True)\n",
      "tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print tensors\n",
    "print(x)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Arithmetic operations\n",
    "y = w * x + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Display gradients\n",
    "print('dy/dw:', w.grad)\n",
    "print('dy/db:', b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4588,  0.8561, -0.8744],\n",
      "        [ 0.6292,  0.3563,  1.2141]], requires_grad=True)\n",
      "tensor([0.8987, 0.2927], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 54.1466, 122.3036],\n",
      "        [ 62.0199, 166.6079],\n",
      "        [104.8099, 173.1985],\n",
      "        [ 52.1514, 124.7130],\n",
      "        [ 53.5295, 162.9014]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2219.8362, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4588,  0.8561, -0.8744],\n",
      "        [ 0.6292,  0.3563,  1.2141]], requires_grad=True)\n",
      "tensor([[ -687.0081, -1429.7102,  -892.9557],\n",
      "        [ 5052.3350,  4530.1270,  3019.5906]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8987, 0.2927], requires_grad=True)\n",
      "tensor([-10.8685,  57.9449])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 54.1466, 122.3036],\n",
      "        [ 62.0199, 166.6079],\n",
      "        [104.8099, 173.1985],\n",
      "        [ 52.1514, 124.7130],\n",
      "        [ 53.5295, 162.9014]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2219.8362, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4656,  0.8704, -0.8654],\n",
      "        [ 0.5787,  0.3110,  1.1839]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1686.8291, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(235.4994, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 61.6818,  74.1907],\n",
       "        [ 74.6087, 105.1717],\n",
       "        [128.7154, 116.4812],\n",
       "        [ 45.3871,  59.4863],\n",
       "        [ 74.6952, 113.9124]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear regression related to gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Linear Regression__<br>\n",
    "In statistics, linear regression is a linear approach to modelling the relationship between a dependent variable and one or more independent variables. Let X be the independent variable and Y be the dependent variable. We will define a linear relationship between these two variables as follows:<br>\n",
    "$$ Y = mX + c $$<br>\n",
    "m is the slope of the line and c is the y intercept. We will use this equation to train our model with a given dataset and predict the value of Y for any given value of X. The challenge is to determine the value of m and c, such that the line corresponding to those values is the best fitting line or gives the minimum error.<br>\n",
    "<br>__Loss Function__<br>\n",
    "The loss is the error in our predicted value of m and c. The goal is to minimize this error to obtain the most accurate value of m and c.<br>\n",
    "We will use the Mean Squared Error function to calculate the loss. There are three steps in this function:<br>\n",
    "Find the difference between the actual y and predicted y value(y = mx + c), for a given x.<br>\n",
    "Square this difference.<br>\n",
    "Find the mean of the squares for every value in X.<br>\n",
    "\n",
    "$${{E} ={\\frac {1}{n}}\\sum _{i=0}^{n}(y_{i}-{\\bar {y_{i}}})^{2}}$$\n",
    "\n",
    "Here $yᵢ$ is the actual value and $ȳᵢ$ is the predicted value. Lets substitute the value of $ ȳᵢ$:\n",
    "$${{E} ={\\frac {1}{n}}\\sum _{i=0}^{n}(y_{i}- (mx + c_{i})^{2}}$$\n",
    "\n",
    "\n",
    "<br>__The Gradient Descent Algorithm__<br>\n",
    "Gradient descent is an iterative optimization algorithm to find the minimum of a function. Here that function is our Loss Function.\n",
    "<br>__Understanding Gradient Descent__<br>\n",
    "\n",
    "<br>Let’s try applying gradient descent to m and c and approach it step by step:<br>\n",
    "1. Initially let m = 0 and c = 0. Let L be our learning rate. This controls how much the value of m changes with each step. L could be a small value like 0.0001 for good accuracy.\n",
    "2. Calculate the partial derivative of the loss function with respect to m, and plug in the current values of x, y, m and c in it to obtain the derivative value D.\n",
    "\n",
    "$${{D_m} ={\\frac {1}{n}}\\sum _{i=0}^{n}2((y_{i} - (mx_{i} + c)){-x_i}})$$\n",
    "\n",
    "$${{D_m} ={\\frac {-2}{n}}\\sum _{i=0}^{n}{x_i}((y_{i} - {\\bar {y_i}}})$$\n",
    "\n",
    "Derivative with respect to m<br>\n",
    "$D_m$ is the value of the partial derivative with respect to m. Similarly lets find the partial derivative with respect to c, $D_c$ :<br>\n",
    "\n",
    "<br>Derivative with respect to c<br>\n",
    "3. Now we update the current value of m and c using the following equation:\n",
    "\n",
    "$$ m = m - L * D_m $$\n",
    "$$ c = c - L * D_c $$\n",
    "\n",
    "4. We repeat this process until our loss function is a very small value or ideally 0 (which means 0 error or 100% accuracy). The value of m and c that we are left with now will be the optimum values.<br>\n",
    "Now going back to our analogy, m can be considered the current position of the person. D is equivalent to the steepness of the slope and L can be the speed with which he moves. Now the new value of m that we calculate using the above equation will be his next position, and L×D will be the size of the steps he will take. When the slope is more steep (D is more) he takes longer steps and when it is less steep (D is less), he takes smaller steps. Finally he arrives at the bottom of the valley which corresponds to our loss = 0.<br>\n",
    "Now with the optimum value of m and c our model is ready to make predictions !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is one of the simplest and widely used algorithms in machine learning, mainly because it can be applied to any function to optimize it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out MSE loss for linear regression. Could we also use this loss for classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Square Error (MSE) is the most commonly used regression loss function. MSE is the sum of squared distances between our target variable and predicted values.<br>\n",
    "The Mean Squared Error (MSE) or Mean Squared Deviation (MSD) of an estimator measures the average of error squares i.e. the average squared difference between the estimated values and true value. It is a risk function, corresponding to the expected value of the squared error loss. It is always non – negative and values close to zero are better. The MSE is the second moment of the error (about the origin) and thus incorporates both the variance of the estimator and its bias.<br>\n",
    "Steps to find the MSE<br>\n",
    "\n",
    "1. Find the equation for the regression line<br>\n",
    "$$\\hat{Y}_i = \\hat{\\beta}_0+\\hat{\\beta}_1{X}_i+\\hat{\\epsilon}_i $$<br>\n",
    "\n",
    "2. Insert X values in the equation found in step 1 in order to get the respective Y values i.e.<br>\n",
    "$$\\hat{Y}_i$$<br>\n",
    "\n",
    "3. Now subtract the new Y values (i.e. $\\hat{Y}_i$) from the original Y values. Thus, found values are the error terms. It is also known as the vertical distance of the given point from the regression line.<br>\n",
    "  $$\\begin{equation*}  Y_i - \\hat{Y}_i  \\end{equation*} $$<br>\n",
    "  \n",
    "4. Square the errors found in step 3.<br>\n",
    "$$  \\begin{equation*}  {(Y_i - \\hat{Y}_i)}^2  \\end{equation*} $$<br>\n",
    "5. Sum up all the squares<br>\n",
    "$$  \\begin{equation*}  \\sum_{i=1}^{N}(Y_i - \\hat{Y}_i)^2  \\end{equation*} $$<br>\n",
    "6. Divide the value found in step 5 by the total number of observations.<br>\n",
    "$$  \\begin{equation*}  MSE = \\frac{1}{N}\\sum_{i=1}^{N}(Y_i - \\hat{Y}_i)^2  \\end{equation*} $$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy (or softmax loss, but cross-entropy works better) is a better measure than MSE for classification, because the decision boundary in a classification task is large (in comparison with regression). MSE doesn’t punish misclassifications enough but is the right loss for regression, where the distance between two values that can be predicted is small.<br>\n",
    "from a probabilistic point of view, the cross-entropy arises as the natural cost function to use if you have a sigmoid or softmax nonlinearity in the output layer of your network, and you want to maximize the likelihood of classifying the input data correctly. If instead you assume the target is continuous and normally distributed, and you maximize the likelihood of the output of the net under these assumptions, you get the MSE (combined with a linear output layer). For classification, cross-entropy tends to be more suitable than MSE – the underlying assumptions just make more sense for this setting. That said, you can train a classifier with the MSE loss and it will probably work fine (although it does not play very nicely with the sigmoid/softmax nonlinearities, a linear output layer would be a better choice in that case). For regression problems, you would almost always use the MSE. Another alternative for classification is to use a margin loss, which basically amounts to putting a (linear) SVM on top of your network. ive for classification is to use a margin loss, which basically amounts to putting a (linear) SVM on top of your network.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the Maximum likelihood Estimation for linear regression. How is this related to the MSE loss for linear regression derived in the last point? Derive the relation between them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum likelihood estimation or otherwise noted as MLE is a popular mechanism which is used to estimate the model parameters of a regression model. Other than regression, it is very often used in statics to estimate the parameters of various distribution models.<br>\n",
    "As we have used likelihood calculation to find the best parameter values for various distribution models in statistics, MLE method can also be used to find the best model parameters of a linear regression model. But when calculating parameters values for those statistical distribution models, we knew what kind of distributions was it and the relevant PDF function.<br>\n",
    " When we talk about some values being in a normal distribution, we need to describe more about that normal distribution ; like what kind of normal distribution? More precisely what are the mean and variance of that normal distribution?<br>\n",
    "In linear regression the trick that we do is, we take the model that we need to find, as the mean of the above stated normal distribution. Because we know how to find MLE values of a mean in a normal distribution.\n",
    "So let’s define our linear model that needed to be estimated as ŷ.<br>\n",
    "$$\\hat{y} = w_0 + w_1x_1 +.......+w_dx_d$$<br>\n",
    "But in linear regression, the mean is a function (ŷ). So you need to understand that for every x value (input) , there will be a number generated by function ŷ as the mean. So from ŷ function, we get a set of values as means. And the important thing to understand from this is that mean for each y value (each result / label) is a different. That is, mean for each y value (label) is the value predicted by our model.<br>\n",
    "As stated above In linear regression, we treat above line ŷ as the “mean” of the normal distribution.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can consider this ŷ data as also in a normal distribution. But this time, their mean values will be them self since they fall along on top of the ŷ line perfectly. And so the variance of these ŷ data (predicted labels) will be 0. So, ŷ~N(XW , 0)\n",
    "We have an error term called ε (residual) which is the distance between predicted value (ŷ) and actual value(y). And there are some important assumptions that we do in linear regression regarding these residuals, and they are:\n",
    "“ Residuals are normally distributed”\n",
    "“ Residuals have an equal variance”\n",
    "“ Means of residuals are 0”\n",
    "So:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img2.png)\n",
    "And we know that y = ŷ + ε and y labels are normally distributed. Our aim is to estimate the best values for mean and variance of normal distribution y. Let’s get the mean and variance of y in terms of ŷ and ε normal distributions. We know the mean is termed as expectation. So let’s get the expectation of y=ŷ + ε equation in order to find the mean (expectation) of y.\n",
    "E(y) = E(ŷ + ε)\n",
    "E(y) = E(ŷ) + E(ε)\n",
    "E(y) = XW + 0 = XW\n",
    "And,\n",
    "Variance(y) = Variance( ŷ + ε )\n",
    "Variance(y) = Variance( ŷ )+ Variance( ε )\n",
    "Variance(y) = 0 + σ²\n",
    "So we can say that y is a normal distribution with mean XW and variance σ²."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img3.png)\n",
    "Now let’s calculate the MLEs for XW and σ² as we did in previous example. But note that here we hava n data points (in earlier example we had only 3), and each of those data point are of dimension d.\n",
    "![](img4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As y is a normal distribution,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](!img1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s get natural logarithms in both sides so that we get the log likelihood,\n",
    "![](img5.png)\n",
    "In order to estimate the best set of weights (weight matrix), let’s partially differentiate the above equation from w.\n",
    "![](img6.png)\n",
    "Optimal values for W is when\n",
    "![](img7.png)\n",
    "Then,\n",
    "![](img8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have found the optimal values for Ws in our model. And that is the main aim of linear regression since once found the w matrix, we can predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the likelihood function for linear classification. What is the drawback of using MSE loss here? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply MLE to linear regression, the objective is to find the best line that fits the data points. But first, let us make some assumptions. We assume each label, $y_i$, is gaussian distributed with mean, $x^T_iθ$ and variance, $σ^2$, given by<br>\n",
    "\n",
    "$$y_i=\\mathcal{N}(x^T_i\\theta,σ^2)=x^T_i\\theta+\\mathcal{N}(0,σ^2)$$\n",
    "$$prediction,\\hat{y}_i=x^T_i\\theta$$<br>\n",
    "where  $x_i$ is a vector of form $(x^1_i=1,x^2_i)$.<br>\n",
    "\n",
    "The mean, $x^T_i\\theta$ represents the best fit line. The data points will vary about the line, and the second term, captures this variance, $\\mathcal{N}(0,σ^2)$.<br>\n",
    "Learning<br>\n",
    "If we assume that each point yi is gaussian distributed, the process of learning becomes the process of maximizing the product of the individual probabilities, which is equivalent to maximizing the log likelihood. We switch to log space, as it is more convenient and it removes the exponential in the gaussian distribution.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "As the data points are independent, we can write the joint probability distribution of y,θ,σ as,\n",
    "\n",
    "$$p(y|X,θ,σ)=∏i=1np(y_i|x_i,θ,σ)$$\n",
    "$$p(y|X,θ,σ)=∏i=1n(2πσ^2)−1/2e−12σ2(yi−xTiθ)2$$\n",
    "rewriting in vector form,\n",
    "\n",
    "$$p(y|X,θ,σ)={(2πσ^2)−1/2e}−1/2σ^2(y−Xθ)T(y−Xθ)$$\n",
    "Log likelihood,\n",
    "\n",
    "l(θ)=−n2log(2πσ2)−12σ2(Y−Xθ)T(Y−Xθ)\n",
    "The first term is a constant and the second term is a parabola, the peak (maxima) of which can be found by equating the derivative of l(θ) to zero. Equating first derivative to zero, we get,\n",
    "\n",
    "dl(θ)dθ=0=−12σ2(0−2XTY+XTXθ)\n",
    "we get,<br>\n",
    "\n",
    "$$\\hat{\\theta}_{ML}=(X^TX)^{−1}X^TY$$\n",
    "Finally, we reach our goal of finding the best model for linear regression. This equation is commonly known as the normal equation. The same equation can be derived using the least squares method (perhaps in another post).<br>\n",
    "\n",
    "Similarly, we can get the maximum likelihood of variance, $σ^2$, by differentiating log likelihood with respect to σ and equating to zero.<br>\n",
    "\n",
    "$$\\hat{\\sigma}^2_{ML}=\\frac{1}{n}(Y−Xθ)^T(Y−Xθ)=\\frac{1}{n}\\sum_{i=1} n(y_i−x_iθ)^2$$<br>\n",
    "This gives us the standard estimate of variance in the training data.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can gradient descent be used to find the parameters for linear regression? What about linear classification? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, gradient descent can be used to find the parameters for linear regression. Gradient descent can also be used in linear classification as the loss function is differentiable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are normal equations? Is it the same as least squares? Explain.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Equation is an analytical approach to Linear Regression with a Least Square Cost Function. We can directly find out the value of θ without using Gradient Descent. Following this approach is an effective and a time-saving option when are working with a dataset with small features.<br>\n",
    "\n",
    "__Normal Equation is a follows :__\n",
    "\n",
    "$$ \\theta = ({X}^T{X})^{-1}.({X}^T{y}) $$\n",
    "\n",
    "In the above equation,<br>\n",
    "$θ$ : hypothesis parameters that define it the best.<br>\n",
    "$X$ : Input feature value of each instance.<br>\n",
    "$Y$ : Output value of each instance.<br>\n",
    "\n",
    "__Maths Behind the equation –__\n",
    "Given the hypothesis function <br>\n",
    "\n",
    "$$ h(\\theta) = \\theta_0{x_0} + \\theta_1{x_1}+...... + \\theta_n{x_n} $$\n",
    "\n",
    "\n",
    "where,<br>\n",
    "$n$ : the no. of features in the data set.<br>\n",
    "${x_0}$ : 1 (for vector multiplication)<br>\n",
    "\n",
    "Notice that this is dot product between θ and x values. So for the convenience to solve we can write it as :<br>\n",
    "\n",
    "\n",
    "$$ h(\\theta) = \\theta ^ T{x}$$\n",
    "\n",
    "\n",
    "\n",
    "The motive in Linear Regression is to minimize the cost function :<br>\n",
    "\n",
    " $$J(\\Theta) = \\frac{1}{2m} \\sum_{i = 1}^{m} \\frac{1}{2} [h_{\\Theta}(x^{(i)}) - y^{(i)}]^{2} $$ \n",
    "where,<br>\n",
    "$x_i$ : the input value of iih training example.<br>\n",
    "$m$ : no. of training instances<br>\n",
    "$n$ : no. of data-set features<br>\n",
    "$y_i$ : the expected result of ith instance<br>\n",
    "\n",
    "Let us representing cost function in a vector form<br>\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "h_\\theta ({x}^0) \\\\\n",
    "h_\\theta ({x}^1) \\\\\n",
    ".......\\\\\n",
    "h_\\theta ({x}^m) \\\\\n",
    "\\end{bmatrix}  \n",
    " - \\begin{bmatrix} \n",
    "({y}^0) \\\\\n",
    "({y}^1) \\\\\n",
    ".......\\\\\n",
    "({y}^m) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<br><br>we have ignored 1/2m here as it will not make any difference in the working. It was used for the mathematical convenience while calculation gradient descent. But it is no more needed here.<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\theta ^ T ({x}^0) \\\\\n",
    "\\theta ^ T ({x}^1) \\\\\n",
    ".......\\\\\n",
    "\\theta ^ T ({x}^m) \\\\\n",
    "\\end{bmatrix} - y\n",
    "$$\n",
    "\n",
    "\n",
    "$\\theta_0 \\begin{pmatrix} 0   \\\\ {x_0} \\end{pmatrix}$ + \n",
    "\n",
    "$\\theta_1\n",
    "\\begin{pmatrix} \n",
    "0   \\\\\n",
    "{x_1}\n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "${x}^i_j$ : value of ${j}^{ih}$ feature in ${i}^{ih}$ training example.\n",
    "\n",
    "This can further be reduced to  $X\\theta - y$<br>\n",
    "But each residual value is squared. We cannot simply square the above expression. As the square of a vector/matrix is not equal to the square of each of its values. So to get the squared value, multiply the vector/matrix with its transpose. So, the final equation derived is\n",
    "\n",
    "$$(X\\theta - y)^{T}(X\\theta - y)$$\n",
    "\n",
    "Therefore, the cost function is\n",
    "\n",
    "$$Cost = (X\\theta - y)^{T}(X\\theta - y) $$\n",
    "\n",
    "So, now getting the value of θ using derivative\n",
    "\n",
    "$$\\frac{\\partial J_{\\theta}}{\\partial {\\theta}} = \\frac{\\partial}{\\partial {\\theta}}{[(X{\\theta}- y)^T{(X{\\theta}- y)}]}$$\n",
    "\n",
    "$$ \\frac{\\partial J_{\\theta}}{\\partial {\\theta}} = 2X^TX\\theta - 2X^Ty$$\n",
    "\n",
    "$$ Cost^{'}(\\theta) = 0 $$\n",
    "\n",
    "$$2X^{T}X{\\theta} - 2X^Ty = 0$$\n",
    "\n",
    "$$2X^{T}X{\\theta} = 2X^Ty$$\n",
    "\n",
    "$$ (X^TX)^{-1}(X^TX){\\theta} = (X^TX)^{-1}.(X^Ty) $$\n",
    "\n",
    "$$\\theta = (X^TX)^{-1}.(X^Ty)$$\n",
    "So, this is the finally derived Normal Equation with θ giving the minimum cost value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is feature scaling needed for linear regression when using gradient descent?  Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. Feature scaling is needed for linear regression when using gradient descent. This is because real-world data can come up in different orders of magnitude. For example, human age might ranges from 0 to 100 years, while income from €10,000 to €10,000,000 (and more). Using such data with such variable range as input features for a linear regression system might slow down the gradient descent algorithm to a crawl. We can speed up gradient descent by scaling features. This is because coeffiecient of linear regression will descend quickly on small ranges and slowly on large ranges, and so will oscillate inefficiently down to the optimum when the variables are very uneven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the MLE approach for logistic regression. How is this related to the binary cross-entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is widely used to model the outcomes of a categorical dependent variable. For categorical variables it is inappropriate to use linear regression because the response values are not measured on a ratio scale and the error terms are not normally distributed. In addition, the linear regression model can generate as predicted values any real number ranging from negative to positive infinity, whereas a categorical variable can only take on a limited number of discrete values within a specified range.\n",
    "Now let’s consider the logistic model (a binary classifier) to describe log-odds using a linear model:\n",
    "$$ \\ln \\frac{p}{1-p}=\\beta_{0}+\\beta_{1} x_{1}+\\cdots+\\beta_{m} x_{m} $$<br>\n",
    "The probability of observing outcome y=1 under this model is given by the following function (sigmoid):<br>\n",
    "$$\n",
    "p \\equiv p(y=1 | \\mathbf{B}, \\mathbf{X})=\\frac{1}{1+e^{-\\left(\\beta_{0}+\\beta_{1} x_{1}+\\cdots+\\beta_{m} x_{m}\\right)}}\n",
    "$$<br>\n",
    "With 0 and 1 being the only possible outcomes, the probability of observing outcome y=0 is simply (1-p):\n",
    "$$\n",
    "p(y=o | \\mathbf{B}, \\mathbf{X})=p^{o}(1-p)^{1-o}\n",
    "$$\n",
    "The likelihood function is given by the product of all individual probabilities:\n",
    "$$\n",
    "\\mathcal{L}=\\prod_{i=1}^{n} p\\left(y=y_{i} | \\mathbf{B}_{i}, \\mathbf{X}_{i}\\right)=\\prod_{i=1}^{n} p_{i}^{y_{i}}\\left(1-p_{i}\\right)^{1-y_{i}}\n",
    "$$\n",
    "It’s easier to maximize the log-likelihood:\n",
    "$$\n",
    "\\ln \\mathcal{L}=\\sum_{i=1}^{n}\\left(y_{i} \\ln p_{i}+\\left(1-y_{i}\\right) \\ln \\left(1-p_{i}\\right)\\right)\n",
    "$$\n",
    "Thus  maximum liklihood estimation yields a familiar loss function (cross-entropy in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
